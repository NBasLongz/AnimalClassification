"""
Script ƒë·ªÉ preprocess ·∫£nh t·ª´ Google cho model
C·∫Øt v√† resize ·∫£nh gi·ªëng dataset AFHQ
"""
import cv2
import numpy as np
from PIL import Image
import sys
import os

# Th√™m backend path
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, os.path.join(BASE_DIR, 'backend'))

def detect_and_crop_face(image_path, output_path=None):
    """
    Detect m·∫∑t ƒë·ªông v·∫≠t v√† crop ƒë·ªÉ gi·ªëng AFHQ dataset
    """
    # Load ·∫£nh
    img = cv2.imread(image_path)
    if img is None:
        print(f"‚ùå Kh√¥ng th·ªÉ load ·∫£nh: {image_path}")
        return None
    
    # Convert sang RGB
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    
    # Detect m·∫∑t ƒë·ªông v·∫≠t b·∫±ng Haar Cascade
    # Download t·ª´: https://github.com/opencv/opencv/tree/master/data/haarcascades
    cascades = [
        'haarcascade_frontalcatface.xml',  # M·∫∑t m√®o
        'haarcascade_frontalface_default.xml',  # C√≥ th·ªÉ detect m·ªôt s·ªë ƒë·ªông v·∫≠t
    ]
    
    faces = []
    for cascade_file in cascades:
        cascade_path = os.path.join(BASE_DIR, 'cascades', cascade_file)
        if os.path.exists(cascade_path):
            cascade = cv2.CascadeClassifier(cascade_path)
            detected = cascade.detectMultiScale(
                cv2.cvtColor(img, cv2.COLOR_BGR2GRAY),
                scaleFactor=1.1,
                minNeighbors=5,
                minSize=(50, 50)
            )
            if len(detected) > 0:
                faces = detected
                break
    
    # N·∫øu kh√¥ng detect ƒë∆∞·ª£c, crop center
    if len(faces) == 0:
        print("‚ö†Ô∏è Kh√¥ng detect ƒë∆∞·ª£c m·∫∑t, crop center square...")
        h, w = img.shape[:2]
        size = min(h, w)
        start_h = (h - size) // 2
        start_w = (w - size) // 2
        cropped = img_rgb[start_h:start_h+size, start_w:start_w+size]
    else:
        # L·∫•y face l·ªõn nh·∫•t
        (x, y, w, h) = max(faces, key=lambda f: f[2] * f[3])
        
        # M·ªü r·ªông crop m·ªôt ch√∫t (nh∆∞ AFHQ)
        margin = int(max(w, h) * 0.3)
        x1 = max(0, x - margin)
        y1 = max(0, y - margin)
        x2 = min(img.shape[1], x + w + margin)
        y2 = min(img.shape[0], y + h + margin)
        
        cropped = img_rgb[y1:y2, x1:x2]
        print(f"‚úì Detected face at ({x}, {y}, {w}, {h})")
    
    # Resize v·ªÅ 512x512 (nh∆∞ AFHQ)
    resized = cv2.resize(cropped, (512, 512))
    
    # Convert to PIL Image
    result = Image.fromarray(resized)
    
    # Save n·∫øu c·∫ßn
    if output_path:
        result.save(output_path)
        print(f"‚úì ƒê√£ l∆∞u ·∫£nh ƒë√£ x·ª≠ l√Ω t·∫°i: {output_path}")
    
    return result


def predict_with_preprocessing(image_path):
    """
    Predict v·ªõi preprocessing gi·ªëng AFHQ
    """
    from api import predict_animal
    
    print(f"\nüì∏ X·ª≠ l√Ω ·∫£nh: {image_path}")
    
    # Preprocess ·∫£nh
    processed_img = detect_and_crop_face(image_path)
    
    if processed_img is None:
        return None
    
    # Predict
    print("\nüîÆ ƒêang d·ª± ƒëo√°n...")
    result = predict_animal(processed_img)
    
    print("\nüìä K·∫øt qu·∫£:")
    for class_name, confidence in sorted(result.items(), key=lambda x: x[1], reverse=True):
        print(f"  {class_name}: {confidence:.4f} ({confidence*100:.2f}%)")
    
    return result


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("S·ª≠ d·ª•ng: python preprocess_and_predict.py <ƒë∆∞·ªùng_d·∫´n_·∫£nh>")
        print("\nV√≠ d·ª•:")
        print("  python preprocess_and_predict.py test_dog.jpg")
        sys.exit(1)
    
    image_path = sys.argv[1]
    
    if not os.path.exists(image_path):
        print(f"‚ùå File kh√¥ng t·ªìn t·∫°i: {image_path}")
        sys.exit(1)
    
    # T·∫°o output path
    base_name = os.path.splitext(os.path.basename(image_path))[0]
    output_path = f"{base_name}_processed.jpg"
    
    # Detect, crop v√† predict
    result = detect_and_crop_face(image_path, output_path)
    
    if result:
        # Predict
        from api import predict_animal
        predictions = predict_animal(result)
        
        print("\n" + "="*60)
        print("K·∫æT QU·∫¢ D·ª∞ ƒêO√ÅN")
        print("="*60)
        for class_name, confidence in sorted(predictions.items(), key=lambda x: x[1], reverse=True):
            bar = "‚ñà" * int(confidence * 50)
            print(f"{class_name:30s} {confidence*100:5.2f}% {bar}")
        print("="*60)
        
        print(f"\nüí° M·∫πo: N·∫øu k·∫øt qu·∫£ kh√¥ng ch√≠nh x√°c, th·ª≠:")
        print("   - S·ª≠ d·ª•ng ·∫£nh close-up m·∫∑t ƒë·ªông v·∫≠t")
        print("   - ·∫¢nh c√≥ background ƒë∆°n gi·∫£n")
        print("   - ·∫¢nh s√°ng, r√µ n√©t")
