import os
import sys
import pickle
import json
import numpy as np
import cv2
from PIL import Image
from skimage.feature import hog, local_binary_pattern

# ƒê∆∞·ªùng d·∫´n g·ªëc c·ªßa project
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

# ƒê∆∞·ªùng d·∫´n ƒë·∫øn model v√† features ƒë√£ l∆∞u
MODELS_DIR = os.path.join(BASE_DIR, "saved_models", "HOG_LBP")
FEATURES_DIR = os.path.join(BASE_DIR, "saved_features", "HOG_LBP")

class AnimalClassifier:
    """
    L·ªõp ƒë·ªÉ load model HOG+LBP SVM v√† th·ª±c hi·ªán d·ª± ƒëo√°n ƒë·ªông v·∫≠t
    """
    
    def __init__(self):
        self.model = None
        self.label_encoder = None
        self.target_size = (128, 128)
        self.classes = []
        self.load_model()
    
    def load_model(self):
        """Load SVM model, label encoder v√† config t·ª´ c√°c file ƒë√£ l∆∞u"""
        
        # Load SVM model
        svm_path = os.path.join(MODELS_DIR, "svm_model.pkl")
        if not os.path.exists(svm_path):
            raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y model t·∫°i: {svm_path}")
        
        with open(svm_path, 'rb') as f:
            self.model = pickle.load(f)
        print(f"‚úì ƒê√£ load SVM model t·ª´: {svm_path}")
        
        # Load label encoder t·ª´ features file
        features_path = os.path.join(FEATURES_DIR, "hog_lbp_features.pkl")
        if not os.path.exists(features_path):
            raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y features t·∫°i: {features_path}")
        
        with open(features_path, 'rb') as f:
            features_data = pickle.load(f)
            self.label_encoder = features_data['label_encoder']
            self.target_size = features_data['target_size']
        
        self.classes = list(self.label_encoder.classes_)
        print(f"‚úì ƒê√£ load label encoder. Classes: {self.classes}")
        print(f"‚úì Target size: {self.target_size}")
        
        # Load config n·∫øu c√≥
        config_path = os.path.join(MODELS_DIR, "config.json")
        if os.path.exists(config_path):
            with open(config_path, 'r') as f:
                config = json.load(f)
                print(f"‚úì ƒê√£ load config: {config}")
    
    def extract_hog_lbp_features(self, image):
        """
        Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng HOG+LBP t·ª´ m·ªôt ·∫£nh
        
        Args:
            image: PIL Image ho·∫∑c numpy array
            
        Returns:
            numpy array ch·ª©a ƒë·∫∑c tr∆∞ng HOG+LBP ƒë√£ n·ªëi
        """
        # Chuy·ªÉn PIL Image sang numpy array n·∫øu c·∫ßn
        if isinstance(image, Image.Image):
            image = np.array(image)
        
        # N·∫øu ·∫£nh l√† RGB, chuy·ªÉn sang BGR cho cv2
        if len(image.shape) == 3 and image.shape[2] == 3:
            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        
        # Resize ·∫£nh v·ªÅ target_size
        image = cv2.resize(image, self.target_size)
        
        # Chuy·ªÉn sang grayscale
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # C·∫•u h√¨nh HOG (ph·∫£i gi·ªëng v·ªõi qu√° tr√¨nh training)
        hog_args = {
            'orientations': 9,
            'pixels_per_cell': (16, 16),
            'cells_per_block': (2, 2),
            'block_norm': 'L2-Hys',
            'feature_vector': True
        }
        
        # Tr√≠ch xu·∫•t HOG features
        hog_feat = hog(gray, **hog_args)
        
        # C·∫•u h√¨nh LBP (ph·∫£i gi·ªëng v·ªõi qu√° tr√¨nh training)
        lbp_radius = 2
        lbp_points = 16
        lbp_method = 'uniform'
        
        # Tr√≠ch xu·∫•t LBP features
        lbp = local_binary_pattern(gray, lbp_points, lbp_radius, lbp_method)
        
        # T√≠nh histogram cho LBP
        n_bins = int(lbp.max() + 1)
        lbp_hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins))
        
        # Chu·∫©n h√≥a histogram LBP (L1 norm)
        lbp_hist = lbp_hist.astype("float")
        lbp_hist /= (lbp_hist.sum() + 1e-7)
        
        # N·ªëi HOG v√† LBP features
        fusion_feat = np.hstack([hog_feat, lbp_hist])
        
        return fusion_feat
    
    def predict(self, image):
        """
        D·ª± ƒëo√°n lo·∫°i ƒë·ªông v·∫≠t t·ª´ ·∫£nh
        
        Args:
            image: PIL Image ho·∫∑c numpy array
            
        Returns:
            dict ch·ª©a confidence scores cho m·ªói class
            Format: {"Ch√≥ (Dog)": 0.8, "M√®o (Cat)": 0.15, "ƒê·ªông v·∫≠t hoang d√£ (Wild)": 0.05}
        """
        # Tr√≠ch xu·∫•t features
        features = self.extract_hog_lbp_features(image)
        
        # Reshape ƒë·ªÉ ph√π h·ª£p v·ªõi input c·ªßa model (1 sample)
        features = features.reshape(1, -1)
        
        # Model l√† Pipeline v·ªõi StandardScaler + SVM
        # Pipeline t·ª± ƒë·ªông scale features tr∆∞·ªõc khi predict
        
        # Ki·ªÉm tra xem model c√≥ h·ªó tr·ª£ predict_proba kh√¥ng
        if hasattr(self.model, 'predict_proba'):
            # N·∫øu model ƒë∆∞·ª£c train v·ªõi probability=True
            probabilities = self.model.predict_proba(features)[0]
        else:
            # N·∫øu kh√¥ng c√≥ predict_proba, d√πng decision_function
            # L∆∞u √Ω: Pipeline c≈©ng c√≥ decision_function
            decision_scores = self.model.decision_function(features)[0]
            
            # Chuy·ªÉn decision scores th√†nh probabilities b·∫±ng softmax
            exp_scores = np.exp(decision_scores - np.max(decision_scores))
            probabilities = exp_scores / exp_scores.sum()
        
        # Map class names sang Vietnamese labels
        class_name_map = {
            'cat': 'M√®o (Cat)',
            'dog': 'Ch√≥ (Dog)',
            'wild': 'ƒê·ªông v·∫≠t hoang d√£ (Wild)'
        }
        
        # T·∫°o dictionary confidence scores
        confidences = {}
        for i, class_name in enumerate(self.classes):
            vietnamese_label = class_name_map.get(class_name, class_name)
            confidences[vietnamese_label] = float(probabilities[i])
        
        return confidences
    
    def predict_class(self, image):
        """
        D·ª± ƒëo√°n class c·ªßa ·∫£nh (ch·ªâ tr·∫£ v·ªÅ class c√≥ x√°c su·∫•t cao nh·∫•t)
        
        Args:
            image: PIL Image ho·∫∑c numpy array
            
        Returns:
            str: T√™n class v·ªõi confidence cao nh·∫•t
        """
        confidences = self.predict(image)
        predicted_class = max(confidences, key=confidences.get)
        return predicted_class


# Kh·ªüi t·∫°o classifier global ƒë·ªÉ t√°i s·ª≠ d·ª•ng
_classifier = None

def get_classifier():
    """
    L·∫•y instance c·ªßa classifier (singleton pattern)
    """
    global _classifier
    if _classifier is None:
        _classifier = AnimalClassifier()
    return _classifier


def predict_animal(image):
    """
    H√†m prediction ch√≠nh ƒë·ªÉ s·ª≠ d·ª•ng trong frontend
    
    Args:
        image: PIL Image
        
    Returns:
        dict: Confidence scores cho m·ªói class
    """
    classifier = get_classifier()
    return classifier.predict(image)


if __name__ == "__main__":
    # Test code
    print("="*60)
    print("Testing Animal Classifier API")
    print("="*60)
    
    try:
        # Load model
        classifier = get_classifier()
        print("\n‚úì Model loaded successfully!")
        print(f"Classes: {classifier.classes}")
        
        # Test v·ªõi m·ªôt ·∫£nh n·∫øu c√≥
        test_image_path = os.path.join(BASE_DIR, "Data", "afhq_split_80_20", "test", "cat")
        if os.path.exists(test_image_path):
            test_images = [f for f in os.listdir(test_image_path) if f.lower().endswith(('.jpg', '.png'))]
            if test_images:
                test_img_path = os.path.join(test_image_path, test_images[0])
                print(f"\nüì∏ Testing with image: {test_images[0]}")
                
                # Load image
                from PIL import Image
                img = Image.open(test_img_path)
                
                # Predict
                result = predict_animal(img)
                print("\nüîÆ Prediction Results:")
                for class_name, confidence in sorted(result.items(), key=lambda x: x[1], reverse=True):
                    print(f"  {class_name}: {confidence:.4f} ({confidence*100:.2f}%)")
        
        print("\n" + "="*60)
        print("‚úì API is ready to use!")
        print("="*60)
        
    except Exception as e:
        print(f"\n‚ùå Error: {str(e)}")
        import traceback
        traceback.print_exc()
